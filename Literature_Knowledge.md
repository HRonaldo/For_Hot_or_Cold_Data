# 相关的一些知识

## HBase
1. Hbase的特点：HBase 是一种基于 Hadoop 的分布式 NoSQL 数据库系统，具有高可用性、高扩展性和高容错性等优势。它采用了基于列的存储方式，将相同类型的数据存储在同一个列簇中，便于查询和管理。HBase 的数据模型类似于 Google的 Bigtable，支持横向扩展，可以存储海量数据。H B a s e的主要组件包括 HMaster、RegionServer 和 Zookeeper。其中 HMaster 负责管理 RegionServer，RegionServer 担负数据写入、读取等基础操作，Zookeeper 则用于协调 HBase 集群的各种操作

## 三种主要的硬盘类型
1. SSD(Solid State Driver):固态硬盘
- 优点：**读写速度快**；防震抗摔性；低功耗；无噪音；工作温度范围大；轻便
- 缺点：容量小；寿命有限；售价高
2. HDD()：机械键盘（传统键盘）也就是最基本的电脑硬盘
3. HHD(hybrid harddrive):混合硬盘
4. 对比SSD和HHD：
    - 在过去10年中，CPU的性能提升了150倍以上，而传统硬盘才提升了1.5倍不到，这种不均衡的发展，极大的影响了整体性能的提升，尤其在I/O方面，而且SSD（固态硬盘）相比起传统硬盘，它没有磁头，马达，磁盘等一系列的零件，搭载NAND Flash芯片作为存储介质，在运行速度，功耗，轻便等方面是传统硬盘所无法比拟的。
    - 目前传统硬盘因为成本低廉等因素依然占据着硬盘市场的主要份额，然而随着SSD的成本不断的降低，技术不断提升与系统更好的支持等因素，而且目前主流的笔记本电脑也都均配置SATA和mSATA
5. 阿里提出的一种OSS（数据以对象形式存储）：阿里云对象存储OSS（Object Storage Service）是一款海量、安全、低成本、高可靠的云存储服务，可提供99.9999999999%（12个9）的数据持久性，99.995%的数据可用性。多种存储类型供选择，全面优化存储成本。OSS具有与平台无关的RESTful API接口，您可以在任何应用、任何时间、任何地点存储和访问任意类型的数据。您可以使用阿里云提供的API、SDK包或者OSS迁移工具轻松地将海量数据移入或移出阿里云OSS。数据存储到阿里云OSS以后，您可以选择标准存储（Standard）作为移动应用、大型网站、图片分享或热点音视频的主要存储方式，也可以选择成本更低、存储期限更长的低频访问存储（Infrequent Access）、归档存储（Archive）、冷归档存储（Cold Archive）或者深度冷归档（Deep Cold Archive）作为不经常访问数据的存储方式。是一种云端的低成本存储方案
    - <https://help.aliyun.com/zh/oss/product-overview/what-is-oss>阿里OSS的介绍

## 对于云的理解
1. 最基本的三种云模式：
    - 基础设施即服务（Infrastructure as a Service，IaaS）
    - 平台即服务（Platform as a Service，PaaS）
    - 软件即服务（Software as a Service，SaaS）
2. IBM 的软件架构师 Albert Barron 曾经使用披萨作为比喻，解释这个问题。David Ng 进一步引申，让它变得更准确易懂。
    - 在内部自建模型中，想要在家里吃就需要做所有的工作，还需要使用家里的烤箱和食材。
    - 从超市购买食材，就想使用基础设施服务（IaaS）计算模型一样，由厨师使用他们的烤箱预先烘培好食物，但你仍然有义务加热那些膳食并在家里吃（然后清洗餐具）。
    - 在平台即服务（PaaS）模型中，你只需要提供餐具，餐厅老板会提供烤箱，食材，厨师来做饭。
    - 在软件即服务（SaaS）模型中，你去一家餐厅吃饭，在那里所有的服务都会为你准备好，吃完买单，不需要自己准备或清洗餐具。
    ![图片介绍](2019122915481698.png)
3. 每个模型中的关键项就是控制：由谁来负责维护基础设施，以及构建应用程序的技术选择是什么?
在IaaS模型中，云供应商提供基础设施（通常是服务器，存储，宽带），但你需要选择技术并构建最终解决方案；而在SaaS模型中，你就是供应商所提供的服务（比如微信，淘宝等）的被动消费者，无法对技术进行选择，同时也没有任何责任来维护应用程序的基础设施。
4. 新兴的云服务：
    - 函数即服务（Functions as a Service，FaaS）
    - 容器即服务（Container as a Service，CaaS）
    - 基于Faas 的应用程序会使用像亚马逊的 Lambda 技术和 Google Cloud 函数这样的的设施。应用会讲代码块以无服务（serverless）的形式部署。使用Faas平台，无需管理任何服务器基础设施，只需要支付执行函数所需的计算周期。使用容器即服务（CaaS）模型，开发者将微服务作为便携式的虚拟容器（如 Docker）进行构建部署到云供应商。与 IaaS 模型不同，使用 IaaS 的开发人员必须管理部署服务的虚拟机，而 CaaS 则是将服务部署在轻量级的虚拟容器中，云服务提供商会提供运行容器的虚拟服务器，以及用于部署，构建，监控和伸缩容器的综合工具。
5. 一个更加形象的例子
    iaas：我只购买了电脑包含cpu、显卡、内存
    paas：不仅购买了电脑、还给我装好了操作系统、.net等中间件
    saas：不仅装好了操作系统，游戏都给我装好了。

## 对于云计算的理解 <https://blog.csdn.net/qq_46254436/article/details/104537927>这个网站有对云最清晰的讲解
1. 美国国家标准与技术研究院（NIST）定义：云计算是一种模型，它可以实现随时随地、便捷地、随需应变地从可配置计算资源共享池中获取所需的资源（例如，网络、服务器、存储、应用、及服务），资源能够快速供应并释放，使管理资源的工作量和与服务提供商的交互减小到最低限度。举一个形象的例子就是拿钢铁侠举例，钢铁侠有许多的战甲，如：MK 1、MK 2、MK 50等等。每套战甲都有独特的作用。比如打绿巨人用的是反浩克战甲，打灭霸用的是MK 50。我根据敌人的不同选择不一样的战甲这就是按需自助服务；托尼在外出时并不将自己的战甲随身携带，而是需要时通过远程召唤的方式，将战甲召唤到自己身上。无论在哪无论什么时间都可以召唤。这就是广泛的网络接入，我们使用云计算的服务重要的一点就是需要网络的支撑。钢铁侠召唤战甲我就不知道是用网络还是用其他高科技了；钢铁侠的战甲可以拆分成很多的部件、在战斗的过程中，哪个部件坏掉了可以直接更换新的部件。这便是资源池化
在云计算中，底层的硬件（硬盘、网卡、CPU、内存等）组成资源池，供上层使用。资源池内的硬件可以是不用的型号，不同品牌的。就好比KFC中的可乐桶中既可以加百事可乐又可以加可口可乐一样。
快速弹性伸缩可以理解为大师兄的金箍棒，可大可小，可长可短。需要要大的时候就大，需要小的时候就小。云计算中，比如我今天用云电脑打游戏，发现内存不太够，那我就可以立马再去购买相应的内存，给我的主机增加内存。
可计量服务比较的抽象，计量就是将单位统一化，从而使用户能够简单的理解用了多少资源。也可以在计费的时候有统一的标准。但是这样注意一下：计量不等同于计费，但是计量包括计费。
2. 一个简单的等式就是云计算=网络+计算资源（CPU，存储资源），也就是通过互联网将强大的配置好的计算资源分配给每一个人（收费）
3. 云计算中使用的重要技术
    - 互联网：Internet的发展是一切云的最基础底层架构
    - 分布式计算：与集中式计算相对立分布式计算，是用于研究分布式系统的计算机科学领域。分布式系统是将自己所有的组件分布在不同网络的计算机上。这些计算机通过通以消息机制来配合。工作在不同网络中的计算机通过相互协作来完成一个共同的目标。分布式计算将该应用分解成许多小的部分，分配给多台计算机进行处理。这样可以节约整体计算时间，大大提高计算效率。稀有资源可以共享|通过分布式计算可以在多台计算机上平衡计算负载|可以把程序放在最适合运行它的计算机上，**共享稀有资源和平衡负载是计算机分布式计算的核心思想之一**分布式计算和并行计算都是运行并行，来获取更高的性能。将大的任务化为小的任务。如果处理单元共享内存，就称为并行计算，反之就是分布式计算。也有人认为：分布式计算是并行计算的一种特例，也可以这样说。但是分布式的任务互相之间是有独立性的，上一个任务包的结果错误、未返回，并不会对下一个任务包有影响。并行计算每一个Part之间的结果是相互依赖的。所以分布式计算要求的实时性不高，而且可以出现错误。
    - 云计算：属于并行计算，新兴的共享技术的架构方法，可以将巨大的资源池连接在一起，提供各种IT服务。云计算和其他计算都不同，将任务（Job）放在云端，用户只需要通过互联网连接云端就可以完成job的整个过程

## 对于数据库以及云数据库的理解
1. 数据库|数据库管理系统：
    - 数据库用于存放数据，最多的是关系型数据库，关系数据库=多张表+各表之间的关系
    - SQL语言：用于操作数据库中的数据，比如增删改查等等
    - 与自己电脑中文件管理器的区别主要是数据共享，并且具有更大的容量，存储和操作数据的方式也不尽相同
    - 数据库管理系统备注用户组织安排数据以及读取数据，并且保证数据的安全性
2. 云数据库：
    - 由数据库到云数据库的进步：随着云计算的发展和大数据时代的到来，关系型数据库越来越无法满足需要，这主要是由于越来越多的半关系型和非关系型数据需要用数据库进行存储管理，以此同时，分布式技术等新技术的出现也对数据库的技术提出了新的要求，于是越来越多的非关系型数据库就开始出现，这类数据库与传统的关系型数据库在设计和数据结构有了很大的不同， 它们更强调数据库数据的高并发读写和存储大数据，这类数据库一般被称为NoSQL（Not only SQL）数据库。 而传统的关系型数据库在一些传统领域依然保持了强大的生命力。
    - 云数据库的优势：云基础设施的虚拟化、高可用、可弹性调度等特点, 为云数据库提供了开箱即用、可靠可用、按需计费等优势.
    - 按照架构来分种类可以分为云托管数据库 (cloud-hosted database) 以及云原生数据库 (cloud-nativedatabase).
        - 云托管数据库将数据库系统直接部署到云上虚拟机环境中, 具备低成本、易运维、高可靠的优势
        - 在此基础上, 云原生数据库充分利用云基础设施弹性伸缩的特点, 采用计算存储分离的架构, 实现了计算资源和存储资源的独立伸缩, 进一步提升数据库性价比
        - 云原生数据库的关键就在于存算分离
## 冷热数据存储的一些已经有的技术
1. 阿里云瑶池：面向海量数据的极致成本优化-云HBase的一体化冷热分离
    - 重要性：50%的访问都是集中在1%的key上，而一些特殊场景（如双11等）90%的访问都是集中在1%的key上，数据的访问其实集中在部分数据上，体现出一种对数据的倾斜访问
    - 主要作用领域：
        - 海量数据持续增长的业务：如交易历史数据，聊天记录，数据无法做TTL，且单个用户的数据会持续累加。
        - 数据生命周期分明的业务：如监控数据，物流信息，feed收件箱，通常只会查询近期的数据，冷数据仅作为回溯问题使用。
        - 重写轻读的业务：在IOT场景下，车联网中会有大量车辆上报的传感器信息，和实时的轨迹信息，写入吞吐会非常大。但是这些数据往往只是用来做归档，查询的频率非常低。
    - 目前业界的冷热分离方案大多是将数据分为冷库和热库两个库。热库可以采用速度较快，但存储成本比较高的数据库方案如内存数据库Redis，或是MySQL+SSD存储介质。而冷库则采用存储成本比较低的数据库方案，如MySQL+HDD或者是使用HBase等稀疏存储的NoSQL数据库，甚至使用高压缩比的列存数据库。而热库到冷库的数据迁移往往会有以下几个方案。
    - 冷热库定时迁移：用户实时写入热库，并通过其他中间件定时将旧的数据倒入离线库。比如，热库可以是使用SSD介质的MySQL数据库，而冷库可以是使用HDD介质的MySQL数据库，通过**DataX**（DataX 是阿里巴巴开源的一个异构数据源离线同步工具，致力于实现包括关系型数据库(MySQL、Oracle 等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能）等数据迁移工具，定期将热库的数据迁移到HDD介质的冷库中。
    - 刚开始存入数据时候：冷热库双写用户实时双写冷热库，热数据在较短时间后过期（对于不支持TTL的数据库，需要删除清理）。比如热库采用内存数据库Redis，冷库采用MySQL或者海量存储HBase，数据同时写入Redis热库和冷库。Redis中只保留最近7天的数据。查询层先查询在线库，如果在线库无数据则直接查询离线库返回。此方案无需维护一个定时迁移的任务，但是需要依赖用户双写
    - 研究仍然存在的问题:
        - 运维难度增加:用户需要运维热库和冷库两个数据库，在使用增量导出时，用户还需要维护一个定时任务来做数据导出。
        - 数据一致性难以维护:无论是哪种数据同步方案，冷库和热库的数据一致性很难保证。比如说双写方案，用户需要处理一边写成功一边写失败的情况来自行维护两边数据的一致性。定时迁移方案和增强导出由于数据迁移都是异步的，处于冷热边界的数据有可能还在热库中，也有可能已经进入到冷库，多次读取可能会产生不同的结果。也就是各种特殊情况下数据难以保真
        - 用户查询改造成本大:对于业务来说，使用了冷热分离后，数据对于业务来说不再是一个“单库”，用户需要决定这一次查询需要去热库查询还是要去冷库，并且由于冷热数据数据迁移是异步的，用户并不知道数据到底是在热库还是冷库中，通常要冷热库一起查才能得到全量数据。另外，在使用异构的冷库和热库的情况下（如热库使用Redis/MySQL,冷库使用MySQL/HBase），用户必须针对热库和冷库查询开发两套查询接口,开发成本大大上升。
    - 阿里给出的解决方案是冷热数据分离一体化：在同一张表中全透明地实现冷热分离，服务端自动根据用户设置的冷热分界线自动将表中的冷数据归档到冷存储中。也就是普遍讲的冷热数据同构，用户只需要在HBase的表上加上冷热分界线这个设置，即可开启冷热分离功能，有一张表存储了不同数据的索引，并且这个表是同时包含冷和热数据的，然后有一个API接口，可以去读取数据库中的数据，下图是这个结构
        ![冷热数据分离一体化示意图](08be1833a470438f8684723864ecaba9.png)


## 常见的一些冷热识别算法
+ 一个非常好的讲解了目前主要算法的网站：<https://blog.csdn.net/plm199513100/article/details/109563212>
1. 对于冷热数据的识别算法，大多数集中在三类
    - 数据结构特点
    - 统计学特点
    - 机器学习特点
2. 数据结构特点的识别算法，一般主要用于页调度中，在我们所研究的冷热数据分离方面有一定的借鉴意义
    - 页调度：在我们的个人PC上，我们也会存储少量的数据，对于数据的读写访问，显然，内存（RAM）（主存储器）（Memory）是要比存储器（辅助存储器）（Storage）要快的，这就可以类比内存是我们的热库，而磁盘则是我们的冷库，（但是也有较大的区别，例如内存中的数据是无法长时间存储的，一旦断电，内存中的数据就会消失）
        - 关于RAM以及ROM：
            - RAM 的全称是 "Random Access Memory"，它是计算机内部的一种主要内存类型，用于临时存储正在运行的程序和数据。 RAM 具有随机访问的特性，这意味着计算机可以随机访问内存中的任何位置，而不必按顺序逐个访问。这使得 RAM 能够提供快速的读写速度，以支持计算机的实时操作和多任务处理。 RAM 是计算机性能的重要组成部分，因为它直接影响了计算机的运行速度和多任务处理能力。
            - ROM 的全称是 "Read-Only Memory"，它是计算机和其他电子设备中的一种存储器类型。与 RAM（随机存储器）不同，ROM 的主要特点是只读，即其内容在制造或编程后通常不能被修改或擦除。ROM 的作用是存储计算机或设备的固件、固定程序和数据，这些数据对于设备的正常运行至关重要。典型的用途包括存储计算机的启动程序（BIOS），操作系统的关键部分，以及其他设备特定的软件和配置信息。由于 ROM 是只读的，它不会在断电或重新启动后丢失数据，因此非常适用于存储不可更改的核心软件和信息。在一些情况下，还有一种可擦除可编程只读存储器（EPROM，EEPROM等），允许特定数据被擦除和重写，但通常这些存储器类型的修改需要特殊的操作。
            ![计算机中的各种结构](v2-6cbe0ce1ed6a7336de891e9f83ad4269_r.jpg)
            总之，ROM 是一种只读存储器，用于存储计算机和设备的关键数据和程序，这些数据通常不能被用户轻易修改。
            - 读写速度上：硬盘 << 内存条 << 缓存和寄存器
            - 通常情况下，断电不会丢失数据的只有硬盘和主板上的ROM模块，ROM又不能随意写，所以编程中读写文件，指的是对硬盘上文件的读写。硬盘空间比较大，制作相对简单，但速度比CPU上的寄存器或者缓存差很多，所以硬盘的数据要先加载到内存，内存的数据再一点点加载到CPU用于计算，CPU将计算的结果保存在内存中，最终再写入磁盘，这样计算出来的数据就被永久的保存了下来。
    + 关于内存和存储器可以参考下面这篇文章<https://www.51cto.com/article/621350.html>
    - 页调度中常用的算法
        - 了解分页和分段技术
            - 在分段这个技术还没有出现之前，程序运行是需要从内存中分配出足够多的连续的内存，然后把整个程序装载进去如下图所示，某个程序大小是10M，然后，就需要有连续的10M内存空间才能把这个程序装载到内存里面。如果无法找到连续的10M内存，就无法把这个程序装载进内存里面，程序也就无法得到运行，也就是需要一大段连续的空间，这对于我们的内存来讲要求太高了。 
                - 存在的问题：
                    - ①地址空间不隔离：举个例子，假设我有两个程序，一个是程序A，一个是程序B。程序A在内存中的地址假设是0x00000000~0x00000099，程序B在内存中的地址假设是0x00000100~x00000199。那么假设你在程序A中，本来想操作地址0x00000050，不小心手残操作了地址0x00000150，那么，不好的事情或许会发生。你影响了程序A也就罢了，你把程序B也搞了一顿。
                    - ②程序运行时候的地址不确定：因为我们程序每次要运行的时候，都是需要装载到内存中的，假设你在程序中写死了要操作某个地址的内存，例如你要地址0x00000010。但是问题来了，你能够保证你操作的地址0x00000010真的就是你原来想操作的那个位置吗？很可能程序第一次装载进内存的位置是0x00000000~0x00000099，而程序第二次运行的时候，这个程序装载进内存的位置变成了0x00000200~0x00000299，而你操作的0x00000010地址压根就不是属于这个程序所占有的内存
                    - ③内存使用率低下：举个例子，假设你写了3个程序，其中程序A大小为10M，程序B为70M，程序C的大小为30M，但是你的计算机的内存总共有100M这三个程序加起来有110M，显然这三个程序是无法同时存在于内存中的并且最多只能够同时运行两个程序。可能是这样的，程序A占有的内存空间是0x00000000～0x00000009，程序B占有的内存空间是0x00000010～0x00000079。假设这个时候程序C要运行该怎么做？可以把其中的一个程序换出到磁盘上，然后再把程序C装载到内存中。假设是把程序A换出，那么程序C还是无法装载进内存中，因为内存中空闲的连续区域有两块，一块是原来程序A占有的那10M，还有就是从0x00000080～0x00000099这20M，所以，30M的程序C无法装载进内存中。那么，唯一的办法就是把程序B换出，保留程序A，但是，此时会有60M的内存无法利用起来，很浪费对吧
            - 分段：将一个程序分成代码段，数据段，堆栈段什么的，每个段各自管理不同的数据。采用虚拟地址空间技术，举例子就是把虚拟地址空间映射到了物理地址空间，并且你写的程序操作的是虚拟地址，假设，程序A的虚拟地址空间是0x00000100～0x00000200。此时，不仅需要一块连续的物理内存来存放程序A，还需要把程序A的虚拟地址空间映射到（转换为）物理地址空间。可能，程序A的虚拟地址空间从0x00000100～0x00000200映射到了物理地址空间0x00000000～0x00000100。分段技术解决了1和2，**但是本质上他还是需要一段联系的物理存储空间**
            - 分页：分页技术的出现就是为了解决上面的问题③的。分页这个技术仍然是一种虚拟地址空间到物理地址空间映射的机制。但是，粒度更加的小了。单位不是整个程序，而是某个“页”，一段虚拟地址空间组成的某一页映射到一段物理地址空间组成的某一页。简单理解就是可以断断续续的存储在内存中，从而提高了空间利用率 
                - 每个电脑的页的大小是固定的
                    - 页面尺寸小：内存碎片小，内存利用率高（因为页面小，自己琢磨琢磨就好），但页面数目多，使页表过长，占大量内存，管理开销大
                    - 页面尺寸大：页表端，内存利用率低且内存碎片化大（因为页面大，自己琢磨琢磨就好），管理开销小
        - 我们冷热数据的操作对象，其实就是页，哪些页需要调到内存中，就是我们研究的主要问题，从竞争分析的角度来看，页面替换问题是一个典型的在线问题，从某种意义上说，最佳确定性算法是已知的，以下是页调度中几种比较常见的算法
            - 先进先出（FIFO）：使用队列来维护，也就是一个栈的数据结构来维护，先进的页先出，但是这种算法显然性能不佳
            - 最佳置换(OPT)算法：选择的被淘汰页面，将是以后永不使用的，或许是在最长(未来)时间内不再被访问的页面；采用最佳置换算法可保证获得最低的缺页率。但是由于无法预知哪一个页面是未来最长时间内不再被访问的，因而该算法是无法实现的；
            - 最近最久未使用（LRU）算法：用链表，来维护根据页面调入内存后的使用情况进行决策，选择最近最久未使用的页面予以淘汰；该算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问一来所经历的时间T，当需要淘汰一个页面时，选择现有页面中T值最大的，即最近最久未使用的页面予以淘汰。
            - LFU（Least Frequently Used）算法：会对每一个数据都维护一个计数器，核心思想是如果数据最近被访问过，那么将来被访问的几率也更高，当存在热点数据时，LRU的效率很好，但偶发性的、周期性的批量操作会导致LRU命中率急剧下降，缓存污染情况比较严重。
            - CLCOK：又称为最近未使用算法（NUR） 每页设置一个访问位，再将内存中的所有页面都通过链接指针链接成一个循环队列；当某个页面被访问时，其访问位置1。淘汰时，检查其访问位，如果是0，就换出；若为1，则重新将它置0；再按FIFO算法检查下一个页面，到队列中的最后一个页面时，若其访问位仍为1，则再返回到队首再去检查第一个页面。相当于是你被访问了一次之后就可以确保你这一轮不会被淘汰
        - 一些改进之后的算法：
            - LRU-K：使用两个队列，相比LRU，LRU-K需要多维护一个队列，用于记录所有缓存数据被访问的历史。只有当数据的访问次数达到K次的时候，才将数据放入缓存。当需要淘汰数据时，LRU-K会淘汰第K次访问时间距当前时间最大的数据。（访问达到k次之后，才认为是热数据）
                - 对比LRU和LRU-K:LRU认为最近访问过一次的数据就是需要保留在热数据里面的，而LRU-K认为至少需要访问到K次才能留下来
            - 2Q（Two Queues）：维护了两个数据结构，一个是FIFO队列，一个是LRU队列，当数据第一次访问时，2Q算法将数据缓存在FIFO队列里面，当数据第二次被访问时，则将数据从FIFO队列移到LRU队列里面
                - 具体流程：如果数据在FIFO队列中一直没有被再次访问，则最终按照FIFO规则淘汰；如果数据在FIFO队列中被再次访问，则将数据移到LRU队列头部；如果数据在LRU队列再次被访问，则将数据移到LRU队列头部；LRU队列淘汰末尾的数据。
                - 同时关注了存储的时间以及是否访问，访问过的数据会进入LRU，LRU中只要你访问过，就不会被淘汰，而在FIFO中都是长时间没有访问的数据，所以按存储时间淘汰也是一个正常的想法
            - ARC：在输入重复数据较多时，LFU区域长度增加，存储更多的高频词汇内容；而在多次输入不同的数据时，LRU内存区域增加，存储最近使用内容增多。这样就可以实现内存的动态分配了
                - Partition为分隔指针，分离开两个数据结构
                - 需要两个ghost链表来存储已经被踢出两个数据结构的数据，以此来判断是该增加LRU还是LFU的链表的长度
                - 如果没有命中的数据key处于ghost list中，则表示是一次幽灵（phantom）命中，系统知道，这是一个刚刚淘汰的页面，而不是第一次读取或者说很久之前读取的一个页面。ARC用这个信息来调整它自己，以适应当前的I/O模式（workload）。这个迹象说明我们的LRU缓存太小了。在这种情况下，LRU链表的长度将会被增加1，并将命中的数据key从ghost list中移除，放入LRU链表的头部。显然，LFU链表的长度将会被减少1。同样，如果一次命中发生在LFU ghost 链表中，它会将LRU链表的长度减一，以此在LFU 链表中加一个可用空间。
            - HotRing：确切的说，这不是一种算法，而是一种新的数据结构。这是阿里在Tair（一种内存数据库）中使用的一种子组件。它本质上是一种改进的hash数据结构，把hash算法中的拉链变成了“拉环”。
                - 下图是一个该数据结构的示意图 ![HotRing数据结构](20201108203340200.png)
                - 介绍以下hash算法中的拉链：链地址法（Chaining）：在数组的每个位置存储一个链表，每个链表包含与该位置相关的所有键-值对，也就是许多键值对应的哈希值是一样的。
                - 该技术把这个链表编程了一个圈，并且让head指针一直指向最热的算法，从而在冷热识别中，只需要对这个指针的值进行迁移即可，本质上来说，是提高了冷热识别的效率，并没有提高太多的准确性。这也引发了我对于我们算法的思考，过去一直在纠结的似乎都是算法的准确性问题，是否也需要关注一下算法的效率问题。
            - 大多数的算法其实就是在结合LRU和LFU，以期望在存储时间和访问频率之间做出一个最佳决策。对于两个数据结构的大小的维护也是一个问题
